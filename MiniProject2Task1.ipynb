{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_JEAGbV36RBp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f97571c4-6ab6-46fb-c812-feb718fb136d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/dataset.zip >> /dev/null"
      ],
      "metadata": {
        "id": "BdJwSXQp6qNK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Check for GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load pre-trained EfficientNet-B0 model and remove the classification head\n",
        "efficientnet = models.efficientnet_b0(pretrained=True)\n",
        "efficientnet.classifier = torch.nn.Sequential(*list(efficientnet.classifier.children())[:-1])  # Remove last layer\n",
        "# Unfreeze all layers for fine-tuning\n",
        "for param in efficientnet.parameters():\n",
        "    param.requires_grad = True  # Unfreeze all layers\n",
        "\n",
        "efficientnet.eval()\n",
        "efficientnet.to(device)  # Move the model to GPU\n",
        "\n",
        "# Transform CIFAR-10 images to 224x224 and normalize to EfficientNet's expected input\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Function to load dataset in mini-batches to manage memory usage\n",
        "def load_train_dataset(filepath, transform, batch_size=64):\n",
        "    dataset = torch.load(filepath)\n",
        "    print(f\"Loaded dataset from {filepath}. Keys:\", dataset.keys())  # Include dataset name in the print statement\n",
        "\n",
        "    # Check if 'data' and 'targets' exist\n",
        "    if 'data' in dataset and 'targets' in dataset:\n",
        "        data, targets = dataset['data'], dataset['targets']\n",
        "    else:\n",
        "        raise KeyError(\"The dataset does not contain the required keys 'data' and 'targets'.\")\n",
        "\n",
        "    # Convert numpy array to PIL Image for each image in the dataset\n",
        "    data = [Image.fromarray(img) for img in data]\n",
        "\n",
        "    # Apply transforms to the data\n",
        "    data = [transform(img) for img in data]\n",
        "\n",
        "    # Create a TensorDataset\n",
        "    dataset = TensorDataset(torch.stack(data), torch.tensor(targets))\n",
        "\n",
        "    # Create a DataLoader\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return dataloader\n",
        "\n",
        "# Extract features in mini-batches\n",
        "def extract_features(dataloader, model):\n",
        "    features = []\n",
        "    with torch.no_grad():  # Disable gradient calculation to save memory\n",
        "        for data, _ in dataloader:\n",
        "            data = data.to(device)  # Move data to GPU\n",
        "            batch_features = model(data)  # Extract features from EfficientNet\n",
        "            features.append(batch_features.cpu())  # Move features back to CPU if needed\n",
        "    return torch.cat(features, dim=0)\n",
        "\n",
        "# LwP Classifier\n",
        "class EuclideanLwPClassifier:\n",
        "    def __init__(self, num_classes, feature_dim):\n",
        "        self.num_classes = num_classes\n",
        "        self.prototypes = np.zeros((num_classes, feature_dim))\n",
        "\n",
        "    def calculate_prototypes(self, features, labels):\n",
        "        for label in range(self.num_classes):\n",
        "            class_features = features[labels == label]\n",
        "            if len(class_features) > 0:\n",
        "                self.prototypes[label] = class_features.mean(axis=0)\n",
        "\n",
        "    def predict(self, features):\n",
        "        distances = np.zeros((features.shape[0], self.num_classes))\n",
        "\n",
        "        # Calculate Euclidean distance between each feature and the prototypes\n",
        "        for label in range(self.num_classes):\n",
        "            for i, feature in enumerate(features):\n",
        "                distances[i, label] = np.linalg.norm(feature - self.prototypes[label])\n",
        "\n",
        "        # Return the class with the minimum Euclidean distance\n",
        "        return np.argmin(distances, axis=1)\n",
        "\n",
        "    def update_prototypes(self, features, predicted_labels, alpha=0.7):\n",
        "        for label in range(self.num_classes):\n",
        "            class_features = features[predicted_labels == label]\n",
        "            if len(class_features) > 0:\n",
        "                # Update prototype with a mix of old and new information (alpha = 0.7)\n",
        "                self.prototypes[label] = alpha * self.prototypes[label] + (1 - alpha) * class_features.mean(axis=0)\n",
        "\n",
        "# Initialize LwP with number of classes (10) and feature dimension from EfficientNet-B0 (1280)\n",
        "num_classes = 10\n",
        "feature_dim = 1280  # EfficientNet-B0 feature dimension\n",
        "lwp_model = EuclideanLwPClassifier(num_classes, feature_dim)\n",
        "\n",
        "# Task 1 Evaluation and Logging\n",
        "def evaluate_and_log_lower_triangle(model, eval_path_template, efficientnet_model, transform, num_datasets=10):\n",
        "    # Initialize an accuracy matrix to store accuracy for each dataset\n",
        "    accuracy_matrix = np.zeros((num_datasets, num_datasets))\n",
        "\n",
        "    # Iterate through each dataset as the training set\n",
        "    for i in range(1, num_datasets + 1):\n",
        "        print(f\"Training with Dataset D^{i} and evaluating...\")\n",
        "\n",
        "        # Update prototypes for the current training dataset\n",
        "        train_dataloader = load_train_dataset(eval_path_template.format(i), transform)\n",
        "        train_features = extract_features(train_dataloader, efficientnet_model).cpu().numpy()\n",
        "        train_targets = [target.cpu().numpy() for _, target in train_dataloader]\n",
        "        train_targets = np.concatenate(train_targets)\n",
        "\n",
        "        # Update the prototypes of the LwP model (model F^i)\n",
        "        model.calculate_prototypes(train_features, train_targets)\n",
        "\n",
        "        # Evaluate the model on all datasets up to the current one (lower triangular)\n",
        "        for j in range(1, i + 1):  # Change the range to evaluate on D^1 to D^i\n",
        "            eval_dataloader = load_train_dataset(eval_path_template.format(j), transform)\n",
        "            eval_features = extract_features(eval_dataloader, efficientnet_model).cpu().numpy()\n",
        "            eval_targets = [target.cpu().numpy() for _, target in eval_dataloader]\n",
        "            eval_targets = np.concatenate(eval_targets)\n",
        "\n",
        "            # Predict labels and calculate accuracy\n",
        "            predicted_labels = model.predict(eval_features)\n",
        "            accuracy = (predicted_labels == eval_targets).mean()\n",
        "            accuracy_matrix[i - 1, j - 1] = accuracy  # Fill the lower triangular matrix\n",
        "\n",
        "            print(f\"Accuracy on Dataset D^{j} after training with Model F^{i}: {accuracy:.4f}\")\n",
        "\n",
        "    # Return the final accuracy matrix\n",
        "    return accuracy_matrix\n",
        "\n",
        "# Final Evaluation of Task 1\n",
        "accuracy_matrix_task1 = evaluate_and_log_lower_triangle(\n",
        "    lwp_model,\n",
        "    '/content/dataset/part_one_dataset/eval_data/{}_eval_data.tar.pth',\n",
        "    efficientnet,\n",
        "    transform,\n",
        "    num_datasets=10\n",
        ")\n",
        "\n",
        "print(\"Lower Triangular Accuracy Matrix (F1-F10):\\n\", accuracy_matrix_task1)\n",
        "\n",
        "# Save the model state after the final training step (after training with all datasets)\n",
        "torch.save(efficientnet.state_dict(), 'f10_model_final.pth')\n",
        "print(\"f10 final model saved successfully.\")\n",
        "\n",
        "# Save the prototypes to a .npy file after calculating them in Task 1\n",
        "np.save('f10_prototypes.npy', lwp_model.prototypes)\n",
        "print(\"f10 prototypes saved successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfYyLdav6073",
        "outputId": "5e5edf35-7b71-44f9-bee4-5a18f217a623"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 72.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with Dataset D^1 and evaluating...\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/1_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-c52aedc9a927>:30: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  dataset = torch.load(filepath)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/1_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^1 after training with Model F^1: 0.8544\n",
            "Training with Dataset D^2 and evaluating...\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/2_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/1_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^1 after training with Model F^2: 0.8412\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/2_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^2 after training with Model F^2: 0.8620\n",
            "Training with Dataset D^3 and evaluating...\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/3_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/1_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^1 after training with Model F^3: 0.8436\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/2_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^2 after training with Model F^3: 0.8532\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/3_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^3 after training with Model F^3: 0.8552\n",
            "Training with Dataset D^4 and evaluating...\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/4_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/1_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^1 after training with Model F^4: 0.8444\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/2_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^2 after training with Model F^4: 0.8568\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/3_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^3 after training with Model F^4: 0.8440\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/4_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^4 after training with Model F^4: 0.8700\n",
            "Training with Dataset D^5 and evaluating...\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/5_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/1_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^1 after training with Model F^5: 0.8420\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/2_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^2 after training with Model F^5: 0.8532\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/3_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^3 after training with Model F^5: 0.8436\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/4_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^4 after training with Model F^5: 0.8524\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/5_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^5 after training with Model F^5: 0.8564\n",
            "Training with Dataset D^6 and evaluating...\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/6_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/1_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^1 after training with Model F^6: 0.8384\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/2_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^2 after training with Model F^6: 0.8492\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/3_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^3 after training with Model F^6: 0.8416\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/4_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^4 after training with Model F^6: 0.8556\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/5_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^5 after training with Model F^6: 0.8500\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/6_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^6 after training with Model F^6: 0.8624\n",
            "Training with Dataset D^7 and evaluating...\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/7_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/1_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^1 after training with Model F^7: 0.8380\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/2_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^2 after training with Model F^7: 0.8460\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/3_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^3 after training with Model F^7: 0.8404\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/4_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^4 after training with Model F^7: 0.8516\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/5_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^5 after training with Model F^7: 0.8452\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/6_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^6 after training with Model F^7: 0.8484\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/7_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^7 after training with Model F^7: 0.8556\n",
            "Training with Dataset D^8 and evaluating...\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/8_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/1_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^1 after training with Model F^8: 0.8412\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/2_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^2 after training with Model F^8: 0.8524\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/3_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^3 after training with Model F^8: 0.8424\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/4_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^4 after training with Model F^8: 0.8540\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/5_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^5 after training with Model F^8: 0.8424\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/6_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^6 after training with Model F^8: 0.8444\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/7_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^7 after training with Model F^8: 0.8432\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/8_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^8 after training with Model F^8: 0.8568\n",
            "Training with Dataset D^9 and evaluating...\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/9_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/1_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^1 after training with Model F^9: 0.8464\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/2_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^2 after training with Model F^9: 0.8560\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/3_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^3 after training with Model F^9: 0.8480\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/4_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^4 after training with Model F^9: 0.8608\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/5_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^5 after training with Model F^9: 0.8524\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/6_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^6 after training with Model F^9: 0.8496\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/7_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^7 after training with Model F^9: 0.8524\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/8_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^8 after training with Model F^9: 0.8464\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/9_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^9 after training with Model F^9: 0.8564\n",
            "Training with Dataset D^10 and evaluating...\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/10_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/1_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^1 after training with Model F^10: 0.8388\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/2_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^2 after training with Model F^10: 0.8472\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/3_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^3 after training with Model F^10: 0.8404\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/4_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^4 after training with Model F^10: 0.8488\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/5_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^5 after training with Model F^10: 0.8460\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/6_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^6 after training with Model F^10: 0.8468\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/7_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^7 after training with Model F^10: 0.8452\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/8_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^8 after training with Model F^10: 0.8436\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/9_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^9 after training with Model F^10: 0.8324\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/10_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^10 after training with Model F^10: 0.8628\n",
            "Lower Triangular Accuracy Matrix (F1-F10):\n",
            " [[0.8544 0.     0.     0.     0.     0.     0.     0.     0.     0.    ]\n",
            " [0.8412 0.862  0.     0.     0.     0.     0.     0.     0.     0.    ]\n",
            " [0.8436 0.8532 0.8552 0.     0.     0.     0.     0.     0.     0.    ]\n",
            " [0.8444 0.8568 0.844  0.87   0.     0.     0.     0.     0.     0.    ]\n",
            " [0.842  0.8532 0.8436 0.8524 0.8564 0.     0.     0.     0.     0.    ]\n",
            " [0.8384 0.8492 0.8416 0.8556 0.85   0.8624 0.     0.     0.     0.    ]\n",
            " [0.838  0.846  0.8404 0.8516 0.8452 0.8484 0.8556 0.     0.     0.    ]\n",
            " [0.8412 0.8524 0.8424 0.854  0.8424 0.8444 0.8432 0.8568 0.     0.    ]\n",
            " [0.8464 0.856  0.848  0.8608 0.8524 0.8496 0.8524 0.8464 0.8564 0.    ]\n",
            " [0.8388 0.8472 0.8404 0.8488 0.846  0.8468 0.8452 0.8436 0.8324 0.8628]]\n",
            "f10 final model saved successfully.\n",
            "f10 prototypes saved successfully.\n"
          ]
        }
      ]
    }
  ]
}