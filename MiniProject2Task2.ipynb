{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLc_ENS5LDTk",
        "outputId": "ce5c3a15-0091-46a3-8df6-8d491650f782"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/dataset.zip >> /dev/null"
      ],
      "metadata": {
        "id": "P6-KYdy1LN28"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Check for GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load pre-trained EfficientNet-B0 model and remove the classification head\n",
        "efficientnet = models.efficientnet_b0(pretrained=False)  # Set pretrained=False since we're loading custom weights\n",
        "efficientnet.classifier = torch.nn.Sequential(*list(efficientnet.classifier.children())[:-1])  # Remove last layer\n",
        "efficientnet.eval()  # Set model to evaluation mode\n",
        "efficientnet.to(device)  # Move the model to GPU\n",
        "\n",
        "# Load the saved model state (f10 from Task 1)\n",
        "efficientnet.load_state_dict(torch.load('/content/f10_model_final.pth'))\n",
        "efficientnet.eval()  # Ensure the model is in evaluation mode\n",
        "\n",
        "# Load the saved prototypes for f10\n",
        "class EuclideanLwPClassifier:\n",
        "    def __init__(self, num_classes, feature_dim):\n",
        "        self.num_classes = num_classes\n",
        "        self.prototypes = np.zeros((num_classes, feature_dim))\n",
        "\n",
        "    def calculate_prototypes(self, features, labels):\n",
        "        for label in range(self.num_classes):\n",
        "            class_features = features[labels == label]\n",
        "            if len(class_features) > 0:\n",
        "                self.prototypes[label] = class_features.mean(axis=0)\n",
        "\n",
        "    def predict(self, features):\n",
        "        distances = np.zeros((features.shape[0], self.num_classes))\n",
        "\n",
        "        # Calculate Euclidean distance between each feature and the prototypes\n",
        "        for label in range(self.num_classes):\n",
        "            for i, feature in enumerate(features):\n",
        "                distances[i, label] = np.linalg.norm(feature - self.prototypes[label])\n",
        "\n",
        "        # Return the class with the minimum Euclidean distance\n",
        "        return np.argmin(distances, axis=1)\n",
        "\n",
        "    def update_prototypes(self, features, predicted_labels, alpha=0.7):\n",
        "        for label in range(self.num_classes):\n",
        "            class_features = features[predicted_labels == label]\n",
        "            if len(class_features) > 0:\n",
        "                # Update prototype with a mix of old and new information (alpha = 0.7)\n",
        "                self.prototypes[label] = alpha * self.prototypes[label] + (1 - alpha) * class_features.mean(axis=0)\n",
        "\n",
        "# Initialize LwP with number of classes (10) and feature dimension from EfficientNet-B0 (1280)\n",
        "num_classes = 10\n",
        "feature_dim = 1280  # EfficientNet-B0 feature dimension\n",
        "lwp_model = EuclideanLwPClassifier(num_classes, feature_dim)\n",
        "\n",
        "# Load prototypes from Task 1 (for f10)\n",
        "lwp_model.prototypes = np.load('/content/f10_prototypes.npy')\n",
        "\n",
        "\n",
        "# Define CIFAR-10 transform (same as Task 1)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Function to load dataset in mini-batches to manage memory usage\n",
        "def load_train_dataset(filepath, transform, batch_size=64):\n",
        "    \"\"\"\n",
        "    Load datasets from the given file path and apply transformations.\n",
        "    \"\"\"\n",
        "    dataset = torch.load(filepath)\n",
        "    print(f\"Loaded dataset from {filepath}. Keys: {dataset.keys()}\")\n",
        "\n",
        "    if 'data' in dataset:\n",
        "        data = dataset['data']\n",
        "    else:\n",
        "        raise KeyError(\"The dataset does not contain the required key 'data'.\")\n",
        "\n",
        "    if 'targets' in dataset:\n",
        "        targets = dataset['targets']\n",
        "    else:\n",
        "        print(\"No 'targets' found in dataset. Using placeholder labels.\")\n",
        "        targets = np.zeros(len(data))  # Placeholder for unlabeled datasets\n",
        "\n",
        "    data = [transform(Image.fromarray(img)) for img in data]\n",
        "    dataset = TensorDataset(torch.stack(data), torch.tensor(targets, dtype=torch.long))\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "    return dataloader\n",
        "\n",
        "# Extract features in mini-batches\n",
        "def extract_features(dataloader, model):\n",
        "    features = []\n",
        "    with torch.no_grad():  # Disable gradient calculation to save memory\n",
        "        for data, _ in dataloader:\n",
        "            data = data.to(device)  # Move data to GPU\n",
        "            batch_features = model(data)  # Extract features from EfficientNet\n",
        "            features.append(batch_features.cpu())  # Move features back to CPU if needed\n",
        "    return torch.cat(features, dim=0)\n",
        "\n",
        "\n",
        "# Define the evaluation function for Task 2 (held-out datasets)\n",
        "def evaluate_task2_with_f11_to_f20(model, eval_paths_part_one, eval_paths_part_two, efficientnet_model, transform, num_datasets=10, start_from=11, num_task2_datasets=10):\n",
        "    # Initialize the accuracy matrix for Task 2 (10 models x 20 datasets)\n",
        "    accuracy_matrix_task2 = np.zeros((num_task2_datasets, num_datasets + num_task2_datasets))\n",
        "\n",
        "    # Iterate over each new dataset from D'11 to D'20\n",
        "    for i in range(start_from, start_from + num_task2_datasets):  # Starting from D'11 to D'20\n",
        "        print(f\"Training and Evaluating on Dataset D'{i}...\")\n",
        "\n",
        "        # Load and extract features for the current dataset (D'i) from eval_paths_part_two\n",
        "        train_dataloader = load_train_dataset(eval_paths_part_two.format(i - start_from + 1), transform)  # Adjust indexing for part_two\n",
        "        train_features = extract_features(train_dataloader, efficientnet_model).cpu().numpy()\n",
        "        train_targets = [target.cpu().numpy() for _, target in train_dataloader]\n",
        "        train_targets = np.concatenate(train_targets)\n",
        "\n",
        "        # Update the LwP model with new dataset (D'i)\n",
        "        lwp_model.update_prototypes(train_features, train_targets)\n",
        "\n",
        "        # Predict labels and calculate accuracy for D'i with the updated model\n",
        "        predicted_labels = lwp_model.predict(train_features)\n",
        "        accuracy = (predicted_labels == train_targets).mean()\n",
        "\n",
        "        # Store accuracy for D'i\n",
        "        accuracy_matrix_task2[i - start_from, i - start_from] = accuracy  # Store accuracy for D'i (diagonal)\n",
        "\n",
        "        # Evaluate the updated model on held-out datasets from D1 to D'i (previous datasets)\n",
        "        for j in range(1, i + 1):  # Evaluate only on D1 to D_i for f_i (not all datasets)\n",
        "            if j <= 10:  # Datasets from part_one (D1 to D10)\n",
        "                eval_dataloader = load_train_dataset(eval_paths_part_one.format(j), transform)\n",
        "            else:  # Datasets from part_two (D11 to D20)\n",
        "                eval_dataloader = load_train_dataset(eval_paths_part_two.format(j - 10), transform)\n",
        "\n",
        "            eval_features = extract_features(eval_dataloader, efficientnet_model).cpu().numpy()\n",
        "            eval_targets = [target.cpu().numpy() for _, target in eval_dataloader]\n",
        "            eval_targets = np.concatenate(eval_targets)\n",
        "\n",
        "            # Predict labels and calculate accuracy\n",
        "            predicted_labels = lwp_model.predict(eval_features)\n",
        "            accuracy = (predicted_labels == eval_targets).mean()\n",
        "            accuracy_matrix_task2[i - start_from, j - 1] = accuracy\n",
        "\n",
        "            print(f\"Accuracy on Dataset D^{j} after training with Model f{i}: {accuracy:.4f}\")\n",
        "\n",
        "    return accuracy_matrix_task2\n",
        "\n",
        "\n",
        "# Task 2 Evaluation (held-out datasets)\n",
        "accuracy_matrix_task2 = evaluate_task2_with_f11_to_f20(\n",
        "    lwp_model,\n",
        "    '/content/dataset/part_one_dataset/eval_data/{}_eval_data.tar.pth',  # Paths for D1 to D10 from part_one_dataset\n",
        "    '/content/dataset/part_two_dataset/eval_data/{}_eval_data.tar.pth',  # Paths for D11 to D20 from part_two_dataset\n",
        "    efficientnet,\n",
        "    transform,\n",
        "    num_datasets=10,  # D1 to D10\n",
        "    start_from=11,     # Start from D'11 (after Task 1)\n",
        "    num_task2_datasets=10  # Evaluate for D'11 to D'20\n",
        ")\n",
        "\n",
        "print(\"Accuracy Matrix for Task 2 (F11-F20):\")\n",
        "print(accuracy_matrix_task2)\n",
        "\n",
        "# Optionally, save the accuracy matrix for Task 2\n",
        "np.save('accuracy_matrix_task2.npy', accuracy_matrix_task2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqilXkpGMxI8",
        "outputId": "957a4a70-7ac8-4f41-8650-53a1e59f4d97"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-3-09ae54bda9be>:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  efficientnet.load_state_dict(torch.load('/content/f10_model_final.pth'))\n",
            "<ipython-input-3-09ae54bda9be>:72: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  dataset = torch.load(filepath)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and Evaluating on Dataset D'11...\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/1_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/1_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^1 after training with Model f11: 0.8352\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/2_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^2 after training with Model f11: 0.8432\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/3_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^3 after training with Model f11: 0.8368\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/4_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^4 after training with Model f11: 0.8464\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/5_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^5 after training with Model f11: 0.8460\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/6_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^6 after training with Model f11: 0.8440\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/7_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^7 after training with Model f11: 0.8412\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/8_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^8 after training with Model f11: 0.8336\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/9_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^9 after training with Model f11: 0.8292\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/10_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^10 after training with Model f11: 0.8576\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/1_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^11 after training with Model f11: 0.7196\n",
            "Training and Evaluating on Dataset D'12...\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/2_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/1_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^1 after training with Model f12: 0.8252\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/2_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^2 after training with Model f12: 0.8376\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/3_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^3 after training with Model f12: 0.8324\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/4_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^4 after training with Model f12: 0.8384\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/5_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^5 after training with Model f12: 0.8396\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/6_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^6 after training with Model f12: 0.8444\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/7_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^7 after training with Model f12: 0.8304\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/8_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^8 after training with Model f12: 0.8240\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/9_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^9 after training with Model f12: 0.8240\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/10_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^10 after training with Model f12: 0.8492\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/1_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^11 after training with Model f12: 0.7144\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/2_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^12 after training with Model f12: 0.6460\n",
            "Training and Evaluating on Dataset D'13...\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/3_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/1_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^1 after training with Model f13: 0.8252\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/2_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^2 after training with Model f13: 0.8368\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/3_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^3 after training with Model f13: 0.8288\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/4_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^4 after training with Model f13: 0.8384\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/5_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^5 after training with Model f13: 0.8352\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/6_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^6 after training with Model f13: 0.8440\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/7_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^7 after training with Model f13: 0.8312\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/8_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^8 after training with Model f13: 0.8212\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/9_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^9 after training with Model f13: 0.8232\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/10_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^10 after training with Model f13: 0.8456\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/1_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^11 after training with Model f13: 0.7136\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/2_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^12 after training with Model f13: 0.6348\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/3_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^13 after training with Model f13: 0.7612\n",
            "Training and Evaluating on Dataset D'14...\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/4_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/1_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^1 after training with Model f14: 0.8248\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/2_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^2 after training with Model f14: 0.8316\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/3_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^3 after training with Model f14: 0.8272\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/4_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^4 after training with Model f14: 0.8380\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/5_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^5 after training with Model f14: 0.8312\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/6_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^6 after training with Model f14: 0.8396\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/7_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^7 after training with Model f14: 0.8256\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/8_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^8 after training with Model f14: 0.8220\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/9_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^9 after training with Model f14: 0.8208\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/10_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^10 after training with Model f14: 0.8420\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/1_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^11 after training with Model f14: 0.7164\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/2_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^12 after training with Model f14: 0.6224\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/3_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^13 after training with Model f14: 0.7608\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/4_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^14 after training with Model f14: 0.7860\n",
            "Training and Evaluating on Dataset D'15...\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/5_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/1_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^1 after training with Model f15: 0.8340\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/2_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^2 after training with Model f15: 0.8420\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/3_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^3 after training with Model f15: 0.8368\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/4_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^4 after training with Model f15: 0.8448\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/5_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^5 after training with Model f15: 0.8416\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/6_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^6 after training with Model f15: 0.8428\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/7_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^7 after training with Model f15: 0.8344\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/8_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^8 after training with Model f15: 0.8316\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/9_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^9 after training with Model f15: 0.8304\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/10_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^10 after training with Model f15: 0.8508\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/1_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^11 after training with Model f15: 0.7176\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/2_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^12 after training with Model f15: 0.6136\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/3_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^13 after training with Model f15: 0.7632\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/4_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^14 after training with Model f15: 0.7876\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/5_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^15 after training with Model f15: 0.8312\n",
            "Training and Evaluating on Dataset D'16...\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/6_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/1_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^1 after training with Model f16: 0.8292\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/2_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^2 after training with Model f16: 0.8372\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/3_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^3 after training with Model f16: 0.8292\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/4_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^4 after training with Model f16: 0.8416\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/5_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^5 after training with Model f16: 0.8392\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/6_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^6 after training with Model f16: 0.8380\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/7_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^7 after training with Model f16: 0.8336\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/8_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^8 after training with Model f16: 0.8280\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/9_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^9 after training with Model f16: 0.8244\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/10_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^10 after training with Model f16: 0.8508\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/1_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^11 after training with Model f16: 0.7096\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/2_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^12 after training with Model f16: 0.6032\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/3_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^13 after training with Model f16: 0.7580\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/4_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^14 after training with Model f16: 0.7860\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/5_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^15 after training with Model f16: 0.8292\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/6_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^16 after training with Model f16: 0.7424\n",
            "Training and Evaluating on Dataset D'17...\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/7_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/1_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^1 after training with Model f17: 0.8288\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/2_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^2 after training with Model f17: 0.8332\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/3_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^3 after training with Model f17: 0.8284\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/4_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^4 after training with Model f17: 0.8364\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/5_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^5 after training with Model f17: 0.8388\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/6_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^6 after training with Model f17: 0.8376\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/7_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^7 after training with Model f17: 0.8324\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/8_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^8 after training with Model f17: 0.8256\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/9_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^9 after training with Model f17: 0.8204\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/10_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^10 after training with Model f17: 0.8440\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/1_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^11 after training with Model f17: 0.7192\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/2_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^12 after training with Model f17: 0.6000\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/3_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^13 after training with Model f17: 0.7580\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/4_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^14 after training with Model f17: 0.7864\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/5_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^15 after training with Model f17: 0.8264\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/6_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^16 after training with Model f17: 0.7348\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/7_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^17 after training with Model f17: 0.7524\n",
            "Training and Evaluating on Dataset D'18...\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/8_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/1_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^1 after training with Model f18: 0.8296\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/2_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^2 after training with Model f18: 0.8296\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/3_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^3 after training with Model f18: 0.8256\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/4_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^4 after training with Model f18: 0.8336\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/5_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^5 after training with Model f18: 0.8332\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/6_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^6 after training with Model f18: 0.8364\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/7_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^7 after training with Model f18: 0.8216\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/8_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^8 after training with Model f18: 0.8232\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/9_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^9 after training with Model f18: 0.8160\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/10_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^10 after training with Model f18: 0.8404\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/1_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^11 after training with Model f18: 0.7160\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/2_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^12 after training with Model f18: 0.6032\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/3_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^13 after training with Model f18: 0.7588\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/4_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^14 after training with Model f18: 0.7872\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/5_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^15 after training with Model f18: 0.8256\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/6_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^16 after training with Model f18: 0.7348\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/7_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^17 after training with Model f18: 0.7520\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/8_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^18 after training with Model f18: 0.7400\n",
            "Training and Evaluating on Dataset D'19...\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/9_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/1_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^1 after training with Model f19: 0.8268\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/2_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^2 after training with Model f19: 0.8280\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/3_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^3 after training with Model f19: 0.8268\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/4_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^4 after training with Model f19: 0.8276\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/5_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^5 after training with Model f19: 0.8360\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/6_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^6 after training with Model f19: 0.8360\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/7_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^7 after training with Model f19: 0.8208\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/8_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^8 after training with Model f19: 0.8216\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/9_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^9 after training with Model f19: 0.8164\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/10_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^10 after training with Model f19: 0.8372\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/1_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^11 after training with Model f19: 0.7024\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/2_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^12 after training with Model f19: 0.5808\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/3_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^13 after training with Model f19: 0.7460\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/4_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^14 after training with Model f19: 0.7892\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/5_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^15 after training with Model f19: 0.8160\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/6_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^16 after training with Model f19: 0.7272\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/7_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^17 after training with Model f19: 0.7448\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/8_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^18 after training with Model f19: 0.7376\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/9_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^19 after training with Model f19: 0.6656\n",
            "Training and Evaluating on Dataset D'20...\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/10_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/1_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^1 after training with Model f20: 0.8352\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/2_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^2 after training with Model f20: 0.8412\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/3_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^3 after training with Model f20: 0.8364\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/4_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^4 after training with Model f20: 0.8396\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/5_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^5 after training with Model f20: 0.8452\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/6_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^6 after training with Model f20: 0.8432\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/7_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^7 after training with Model f20: 0.8316\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/8_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^8 after training with Model f20: 0.8296\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/9_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^9 after training with Model f20: 0.8236\n",
            "Loaded dataset from /content/dataset/part_one_dataset/eval_data/10_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^10 after training with Model f20: 0.8476\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/1_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^11 after training with Model f20: 0.7040\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/2_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^12 after training with Model f20: 0.5864\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/3_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^13 after training with Model f20: 0.7552\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/4_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^14 after training with Model f20: 0.7876\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/5_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^15 after training with Model f20: 0.8264\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/6_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^16 after training with Model f20: 0.7264\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/7_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^17 after training with Model f20: 0.7420\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/8_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^18 after training with Model f20: 0.7412\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/9_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^19 after training with Model f20: 0.6584\n",
            "Loaded dataset from /content/dataset/part_two_dataset/eval_data/10_eval_data.tar.pth. Keys: dict_keys(['data', 'targets'])\n",
            "Accuracy on Dataset D^20 after training with Model f20: 0.8132\n",
            "Accuracy Matrix for Task 2 (F11-F20):\n",
            "[[0.8352 0.8432 0.8368 0.8464 0.846  0.844  0.8412 0.8336 0.8292 0.8576\n",
            "  0.7196 0.     0.     0.     0.     0.     0.     0.     0.     0.    ]\n",
            " [0.8252 0.8376 0.8324 0.8384 0.8396 0.8444 0.8304 0.824  0.824  0.8492\n",
            "  0.7144 0.646  0.     0.     0.     0.     0.     0.     0.     0.    ]\n",
            " [0.8252 0.8368 0.8288 0.8384 0.8352 0.844  0.8312 0.8212 0.8232 0.8456\n",
            "  0.7136 0.6348 0.7612 0.     0.     0.     0.     0.     0.     0.    ]\n",
            " [0.8248 0.8316 0.8272 0.838  0.8312 0.8396 0.8256 0.822  0.8208 0.842\n",
            "  0.7164 0.6224 0.7608 0.786  0.     0.     0.     0.     0.     0.    ]\n",
            " [0.834  0.842  0.8368 0.8448 0.8416 0.8428 0.8344 0.8316 0.8304 0.8508\n",
            "  0.7176 0.6136 0.7632 0.7876 0.8312 0.     0.     0.     0.     0.    ]\n",
            " [0.8292 0.8372 0.8292 0.8416 0.8392 0.838  0.8336 0.828  0.8244 0.8508\n",
            "  0.7096 0.6032 0.758  0.786  0.8292 0.7424 0.     0.     0.     0.    ]\n",
            " [0.8288 0.8332 0.8284 0.8364 0.8388 0.8376 0.8324 0.8256 0.8204 0.844\n",
            "  0.7192 0.6    0.758  0.7864 0.8264 0.7348 0.7524 0.     0.     0.    ]\n",
            " [0.8296 0.8296 0.8256 0.8336 0.8332 0.8364 0.8216 0.8232 0.816  0.8404\n",
            "  0.716  0.6032 0.7588 0.7872 0.8256 0.7348 0.752  0.74   0.     0.    ]\n",
            " [0.8268 0.828  0.8268 0.8276 0.836  0.836  0.8208 0.8216 0.8164 0.8372\n",
            "  0.7024 0.5808 0.746  0.7892 0.816  0.7272 0.7448 0.7376 0.6656 0.    ]\n",
            " [0.8352 0.8412 0.8364 0.8396 0.8452 0.8432 0.8316 0.8296 0.8236 0.8476\n",
            "  0.704  0.5864 0.7552 0.7876 0.8264 0.7264 0.742  0.7412 0.6584 0.8132]]\n"
          ]
        }
      ]
    }
  ]
}